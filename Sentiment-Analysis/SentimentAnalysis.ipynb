{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc722236-b33a-4072-bb9f-ae9e03c74cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Artharva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 reviews.\n",
      "--- Example of one review ---\n",
      "(['first', 'impressions', ':', 'critically', ',', 'a', 'close', '-', 'to', '-', 'awful', 'film', ',', 'but', 'money', '-', 'wise', ',', 'it', 'has', 'been', 'doing', '(', 'and', 'will', 'continue', 'to', 'do', ')', 'great', '.', 'a', 'sometimes', '-', 'funny', 'film', 'that', 'sags', 'and', 'lags', 'and', 'oftentimes', 'gets', 'boring', '.', 'an', 'orginal', 'plot', 'that', 'grows', 'old', 'real', 'fast', '.', 'one', 'of', 'the', 'only', '90', 'minute', 'films', 'that', 'i', \"'\", 've', 'gotten', 'bored', 'through', '.', 'men', 'in', 'black', 'has', 'defied', 'the', 'odds', '.', 'when', 'i', 'first', 'saw', 'that', 'the', 'flick', 'was', '89', 'minutes', 'long', ',', 'i', 'thought', 'maybe', 'that', 'this', 'was', 'a', 'poor', 'attempt', 'at', 'an', 'independence', 'day', 'type', 'film', 'that', 'just', 'ran', 'out', 'of', 'gas', '.', 'however', ',', 'i', 'now', 'realize', 'that', 'not', 'only', 'did', 'men', 'in', 'black', 'run', 'out', 'of', 'gas', ',', 'but', 'the', 'film', 'in', '90', 'minutes', 'manages', 'to', 'show', 'off', 'a', 'very', 'original', 'idea', '(', 'which', 'summer', 'audiences', 'have', 'embraced', ')', 'that', 'becomes', 'old', 'about', '25', 'minutes', 'into', 'the', 'movie', '.', 'tommy', 'lee', 'jones', 'and', 'will', 'smith', 'play', 'two', '\"', 'government', '\"', 'agents', 'who', 'are', 'responsible', 'for', 'keeping', 'order', 'in', 'alien', 'society', '.', 'the', 'ridiculous', 'plot', 'begins', 'when', 'an', 'alien', '\"', 'bug', '\"', ',', 'played', 'weirdly', 'by', 'vincent', 'd', \"'\", 'onofrio', ',', 'who', 'was', 'so', 'great', 'in', 'full', 'metal', 'jacket', ',', 'lands', 'on', 'earth', 'to', 'retrieve', 'a', 'galaxy', 'that', \"'\", 's', 'somewhere', 'on', '\"', 'orion', \"'\", 's', 'belt', '.', '\"', 'anyway', ',', 'the', 'basic', 'plot', 'revolves', 'around', 'jones', 'and', 'smith', 'to', 'stop', 'this', 'bug', 'from', 'getting', 'the', 'galaxy', ',', 'or', 'a', 'higher', 'power', 'will', 'blow', 'up', 'the', 'earth', '.', 'the', 'premise', 'is', 'ridulous', ',', 'but', 'that', 'is', 'not', 'why', 'i', 'didn', \"'\", 't', 'like', 'this', 'film', '.', 'i', 'love', 'original', 'plots', '.', 'this', 'one', 'had', 'an', 'original', 'one', '.', 'but', 'director', 'barry', 'sonnenfeld', 'did', 'something', 'to', 'this', 'film', 'that', 'ruined', 'its', 'plot', ':', 'he', 'made', 'the', 'film', 'drag', 'and', 'also', 'put', 'in', 'unncessary', 'elements', 'in', 'it', 'that', 'are', 'found', 'in', 'romance', 'films', '.', 'whenever', 'i', 'saw', 'd', \"'\", 'onofrio', \"'\", 's', 'bug', 'stomp', 'and', 'eat', 'people', 'in', 'the', 'film', ',', 'it', 'got', 'terribly', 'boring', 'after', 'a', 'while', '.', 'while', 'smith', \"'\", 's', 'wise', '-', 'cracks', 'did', 'fill', 'in', 'the', 'gaps', ',', 'it', 'wasn', \"'\", 't', 'enough', '.', 'and', 'also', ',', 'i', 'cannot', 'believe', 'the', 'screenwriters', 'elected', 'to', 'have', 'a', 'sub', '-', 'plot', 'where', 'tommy', 'lee', 'jones', 'missed', 'his', 'former', 'lover', 'because', 'as', 'an', 'alien', 'agent', ',', 'they', 'can', \"'\", 't', 'have', 'contact', 'with', 'any', 'humans', 'really', '.', 'and', 'here', 'i', 'see', 'jones', ',', 'at', 'a', 'satellite', 'computer', ',', 'watching', 'his', 'lover', 'plant', 'the', 'garden', '?', 'a', 'sentimental', 'moment', 'in', 'an', 'alien', 'movie', '?', 'nice', 'try', ',', 'but', 'i', 'don', \"'\", 't', 'think', 'so', '.', 'it', 'doesn', \"'\", 't', 'work', 'here', '.', 'it', 'just', 'makes', 'the', 'movie', 'even', 'more', 'ridiculous', 'and', 'even', 'more', 'boring', ':', 'we', 'don', \"'\", 't', 'only', 'have', 'aliens', 'to', 'worry', 'about', ',', 'but', 'now', 'we', 'have', 'jones', \"'\", 's', 'conscience', '.', 'i', 'came', 'into', 'the', 'movie', 'not', 'wanting', 'to', 'see', 'jones', \"'\", 's', 'conscience', ',', 'but', 'wanting', 'to', 'see', 'a', 'real', 'action', 'movie', 'that', 'had', 'lots', 'of', 'aliens', 'in', 'it', '.', 'maybe', 'it', \"'\", 's', 'unfair', 'that', 'i', 'partly', 'judged', 'this', 'movie', 'on', 'what', 'my', 'expectations', 'were', '.', 'nevertheless', ',', 'even', 'though', 'some', 'parts', 'are', 'indeed', 'funny', ',', 'the', 'plot', 'in', 'this', 'movie', 'grew', 'old', 'and', 'boring', '--', 'quick', '.'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Download the data (you only need to do this once)\n",
    "# A new window might pop up, just select 'all' and click 'download'\n",
    "nltk.download('movie_reviews') \n",
    "\n",
    "# Load the reviews into a list\n",
    "# Each item will be a (list_of_words, category)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Shuffle them so we don't have all negatives then all positives\n",
    "import random\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(f\"Loaded {len(documents)} reviews.\")\n",
    "print(\"--- Example of one review ---\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec56d92c-98ed-45dd-9f00-34981abc665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artharva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Artharva\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of cleaned review:\n",
      "('first impression critically close awful film money wise continue great sometimes funny film sag lag oftentimes get boring orginal plot grows old real fast one 90 minute film gotten bored men black defied odds first saw flick 89 minute long thought maybe poor attempt independence day type film ran gas however realize men black run gas film 90 minute manages show original idea summer audience embraced becomes old 25 minute movie tommy lee jones smith play two government agent responsible keeping order alien society ridiculous plot begin alien bug played weirdly vincent onofrio great full metal jacket land earth retrieve galaxy somewhere orion belt anyway basic plot revolves around jones smith stop bug getting galaxy higher power blow earth premise ridulous like film love original plot one original one director barry sonnenfeld something film ruined plot made film drag also put unncessary element found romance film whenever saw onofrio bug stomp eat people film got terribly boring smith wise crack fill gap enough also cannot believe screenwriter elected sub plot tommy lee jones missed former lover alien agent contact human really see jones satellite computer watching lover plant garden sentimental moment alien movie nice try think work make movie even ridiculous even boring alien worry jones conscience came movie wanting see jones conscience wanting see real action movie lot alien maybe unfair partly judged movie expectation nevertheless even though part indeed funny plot movie grew old boring -- quick', 'neg')\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download the necessary NLTK packages (this also might not pop up)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Get our lists of stop words and our lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# This list will hold our cleaned documents\n",
    "cleaned_documents = []\n",
    "\n",
    "for words, category in documents:\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        # 1. Convert to lowercase\n",
    "        lower_word = word.lower()\n",
    "        \n",
    "        # 2. Check if it's not a stop word and not punctuation\n",
    "        if lower_word not in stop_words and lower_word not in string.punctuation:\n",
    "            # 3. Lemmatize the word (e.g., 'running' -> 'run')\n",
    "            cleaned_words.append(lemmatizer.lemmatize(lower_word))\n",
    "    \n",
    "    # Join the words back into a single string (sentence)\n",
    "    cleaned_documents.append((\" \".join(cleaned_words), category))\n",
    "\n",
    "print(\"Example of cleaned review:\")\n",
    "print(cleaned_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196077ce-e553-4b2e-944f-dd2f8835982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Extraction Complete ---\n",
      "Our feature matrix shape: (2000, 5000)\n",
      "This means: (Number of Reviews, Number of Words)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Separate our cleaned text from its labels (positive/negative)\n",
    "X = [doc[0] for doc in cleaned_documents] # The text\n",
    "y = [doc[1] for doc in cleaned_documents] # The labels (pos/neg)\n",
    "\n",
    "# 1. Create the TF-IDF Vectorizer\n",
    "# max_features=5000 means it will only use the 5000 most common words\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# 2. Fit and Transform\n",
    "# .fit() learns the vocabulary from all our text (X)\n",
    "# .transform() converts all the text into a big matrix of numbers\n",
    "X_features = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"--- Feature Extraction Complete ---\")\n",
    "print(f\"Our feature matrix shape: {X_features.shape}\")\n",
    "print(\"This means: (Number of Reviews, Number of Words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f1bc28-6fc5-47d8-937e-857c257f8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Training complete!\n",
      "\n",
      "Accuracy: 87.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.89      0.85      0.87       200\n",
      "         pos       0.86      0.90      0.88       200\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.88      0.88      0.87       400\n",
      "weighted avg       0.88      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split data: 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Create the SVM model\n",
    "# LinearSVC is a type of Support Vector Machine\n",
    "model = LinearSVC()\n",
    "\n",
    "# 2. Train the model on the training data\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 3. Make predictions on the unseen test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed report (Precision, Recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b64b74-7264-4a13-b39a-99b158ae6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review_text):\n",
    "    # 1. Clean the new text using the same steps as before\n",
    "    cleaned_words = []\n",
    "    # We need to split the text into words to process it\n",
    "    words = review_text.split() \n",
    "    \n",
    "    for word in words:\n",
    "        lower_word = word.lower()\n",
    "        if lower_word not in stop_words and lower_word not in string.punctuation:\n",
    "            cleaned_words.append(lemmatizer.lemmatize(lower_word))\n",
    "    \n",
    "    cleaned_review = \" \".join(cleaned_words)\n",
    "    \n",
    "    # 2. Convert the cleaned text to a TF-IDF vector\n",
    "    # IMPORTANT: We use .transform() ONLY. \n",
    "    # We do not use .fit_transform() here because we want to use \n",
    "    # the same 5000-word vocabulary the model was trained on.\n",
    "    review_vector = vectorizer.transform([cleaned_review])\n",
    "    \n",
    "    # 3. Make the prediction\n",
    "    prediction = model.predict(review_vector)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08eeecf-5f7b-4016-8d3f-4a4eb23d77cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 'This movie was absolutely brilliant! Loved the acting.'\n",
      "Prediction: pos\n",
      "--------------------\n",
      "Review: 'It was a total waste of time. The plot was boring and predictable.'\n",
      "Prediction: neg\n",
      "--------------------\n",
      "Review: 'The actors did a great job, but the story was just okay.'\n",
      "Prediction: pos\n"
     ]
    }
   ],
   "source": [
    "# --- Let's try it! ---\n",
    "\n",
    "my_review_1 = \"This movie was absolutely brilliant! Loved the acting.\"\n",
    "print(f\"Review: '{my_review_1}'\")\n",
    "print(f\"Prediction: {predict_sentiment(my_review_1)}\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "my_review_2 = \"It was a total waste of time. The plot was boring and predictable.\"\n",
    "print(f\"Review: '{my_review_2}'\")\n",
    "print(f\"Prediction: {predict_sentiment(my_review_2)}\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# --- Try your own! ---\n",
    "my_review_3 = \"The actors did a great job, but the story was just okay.\"\n",
    "print(f\"Review: '{my_review_3}'\")\n",
    "print(f\"Prediction: {predict_sentiment(my_review_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc66d8-d8a0-4569-8dd3-897185bc2e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
